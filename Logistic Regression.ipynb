{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc54428c",
   "metadata": {},
   "source": [
    "# Logistic Regression & Gradient Descent\n",
    "### Timothy Gao\n",
    "\n",
    "### References\n",
    "\n",
    "- Most materials are derived from here: https://web.stanford.edu/~jurafsky/slp3/5.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "44975011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error function: calculuate cross entropy\n",
    "#mean squared error is used for linear regression\n",
    "\n",
    "#weights: relative importances of features\n",
    "#bais: \"shift\"/location of the activation function\n",
    "#activiation function is sigmoid\n",
    "\n",
    "#numpy for fast mathimatical operations, like dot product\n",
    "import numpy as np\n",
    "\n",
    "#sklearn for breast cancer dataset, evaluation metric, and confusion matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, plot_confusion_matrix\n",
    "\n",
    "#pandas for handlin breast cancer dataset as a DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "#seaborn and matplotlib for graphing\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "82a89bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate for gradient descent\n",
    "#explain why you needa hyperparameter tune this\n",
    "LR = 0.0015\n",
    "\n",
    "#number of random starting points to take\n",
    "n_iters = 100\n",
    "\n",
    "#number of steps to take in GD\n",
    "n_steps = 1000\n",
    "\n",
    "#feature inputs -> dotted weights, + bias -> y = sigmoid(x) -> find_loss(y)\n",
    "\n",
    "#we can write in terms of wegiths and biases (substitute into the find loss function)\n",
    "#feature inputs -> dotted weights, + bias -> y = sigmoid(x) -> find_loss(y) -> \n",
    "\n",
    "weights, biases = 0, 0\n",
    "\n",
    "test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8b4ffdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tanh, ReLU (less computation time)\n",
    "#Why choose sigmoid?\n",
    "\n",
    "#Activation function: \n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Computes sigmoid function to calculate probability based on single-value output of logistic regression\n",
    "    and predictions. \n",
    "    Input: Computed prediction value\n",
    "    Returns: scalar probability between (0, 1)\n",
    "    \"\"\"\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def cross_entropy(predictions, targets, epsilon = 1e-14):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between predicted probabilities and actual 0/1 classifications. \n",
    "    Input: predictions vector of predicted classes' probabilities\n",
    "           targets vector of actual 0/1 classes\n",
    "    Returns: scalar representing loss\n",
    "    \"\"\"\n",
    "    n = predictions.shape[0]\n",
    "    return -(1/n) * np.sum(targets*np.log(predictions + epsilon) + (1-targets)*np.log(1 - predictions + epsilon))\n",
    "\n",
    "#E'(weights, biases)\n",
    "#Other activation function and their derivatives given here: https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
    "def calc_dir(x, bias, predicted, actual):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions. \n",
    "    Input: weights = coefficients for features\n",
    "           bias = single-value added to prediction output     \n",
    "           predicted = predicted 0/1 classes for classification output\n",
    "           actual = actual 0/1 classes for classification output\n",
    "    Returns: tuple of 2 elements\n",
    "             gradient descent vector <dw, db> = vector of greatest descent for weights and biases, respectively\n",
    "    \"\"\"\n",
    "    N = len(weights)\n",
    "\n",
    "    dW = (1/N) * 2 * np.dot(x.T, predicted - actual)\n",
    "    dB = (1/N) * 2 * np.sum(predicted - actual)\n",
    "\n",
    "    return [dW, dB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "fad57fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(weights, bias, x, y, LR, report=False):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to optimize initial starting weight and biases\n",
    "    \n",
    "    Input: x = training set containing input features\n",
    "           y = training set containing expected classification\n",
    "           weights = n-d vector/numpy_array\n",
    "           bias = scalar\n",
    "           LR = scalar, learning rate\n",
    "    Returns: tuple of 2 elements, (weights, bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        #for each row of features, we generate a corresponding number by multiplying each weight by feature value\n",
    "        predicted_vals = np.dot(x, weights.T) + bias\n",
    "        \n",
    "        #for each feature value, we predict its class probability utilizing the sigmoid function\n",
    "        predicted_probs = sigmoid(predicted_vals)\n",
    "\n",
    "        if report:\n",
    "            print(\"On step \" + str(i) + \"th step, loss equals \" + str(cross_entropy(predicted_probs, y)))\n",
    "        \n",
    "        #calculated derivatives\n",
    "        derivs = calc_dir(x, bias, predicted_probs, y)\n",
    "        dW = derivs[0]\n",
    "        dB = derivs[1]\n",
    "        \n",
    "        #\"descent\" down\n",
    "        weights -= LR * dW\n",
    "        bias -= LR * dB\n",
    "        \n",
    "    return [weights, bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "af8a3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, report = False):\n",
    "    \"\"\"\n",
    "    Optimizes weights and biases given initial training set. Utilizes entire training set (must train-test-split beforehand)\n",
    "    \n",
    "    Input: x = model input of training dataset, 2darray containing m samples (entries) and n features\n",
    "           y = expected model output of training dataset, 1darray containing n classification results (0/1)\n",
    "\n",
    "    \"\"\"\n",
    "    global weights, bias\n",
    "    m, n = x.shape\n",
    "    \n",
    "    #we take n_iters random starting points\n",
    "    for _ in range(n_iters):\n",
    "        #random starting points: vector/np_array of size n\n",
    "        weights = np.random.rand(n)\n",
    "        #random starting points: random bias\n",
    "        bias = np.random.rand(1)[0]\n",
    "\n",
    "        res = gradient_descent(weights, bias, x, y, LR, report)\n",
    "        weights = res[0]\n",
    "        bias = res[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c9a32efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(x):\n",
    "    \"\"\"\n",
    "    Utilizes pre-optimized weights and biases to outputs class probability given m entries of nd-vector of features\n",
    "    \n",
    "    Input: m by n matrix of feature\n",
    "    Output: m-d vector of class probabilities for each entry\n",
    "    \"\"\"\n",
    "    predicted_vals = np.dot(x, weights.T) + bias\n",
    "    predicted_probs = sigmoid(predicted_vals)\n",
    "    \n",
    "    return predicted_probs\n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    \"\"\"\n",
    "    Utilizes pre-optimized weights and biases to outputs class given m entries of nd-vector of features\n",
    "    \n",
    "    Input: m by n matrix of feature\n",
    "    Output: m-d vector of 0/1 class for each entry\n",
    "    \"\"\"\n",
    "\n",
    "    x = predict_probs(x)\n",
    "\n",
    "    x = [0 if i < 0.5 else 1 for i in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "b0ac56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "x, y = data.data, data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "21d89014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-296-874f6cf9979a>:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "(114,)\n",
      "0.9210526315789473\n",
      "CPU times: user 9.97 s, sys: 23.2 s, total: 33.2 s\n",
      "Wall time: 6.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(x_train, y_train)\n",
    "\n",
    "y_pred = predict(x_test)\n",
    "print(len(y_pred))\n",
    "print(y_test.shape)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c5669093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "array = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(array, index = ['True Yes', 'True No'],\n",
    "                  columns = ['Predicted Yes', 'Predicted No'])\n",
    "\n",
    "plt.figure()\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "5fcf2ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e5e9eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print( 1.0/(1.0 + np.exp(-97861.91811394185)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "07af1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(-1000.91811394185))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e5adfd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.33680112e+01  1.82310869e+01  7.67189430e+01  2.15161384e+01\n",
      "  5.71030329e-01  6.27937471e-01 -4.16768673e-02 -5.91260239e-02\n",
      "  5.77755167e-01  7.15811249e-01  7.16404190e-01  1.96579642e+00\n",
      " -9.53648456e-01 -3.98923227e+01  1.22873431e-01  8.15008491e-01\n",
      "  1.04418744e-01  4.26012694e-01  9.76907357e-01  4.99809339e-01\n",
      "  1.48358512e+01  2.31395564e+01  7.80994691e+01 -3.66477027e+01\n",
      "  9.42200858e-01  1.91590230e-01 -1.53367077e-01  7.58421962e-01\n",
      "  4.48068387e-01  3.56161320e-01]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "d9dffffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9808801287972688"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3d813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
