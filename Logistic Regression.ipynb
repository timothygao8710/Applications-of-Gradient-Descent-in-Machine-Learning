{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b2e2f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error function: calculuate cross entropy\n",
    "#mean squared error is used for linear regression\n",
    "\n",
    "#weights: relative importances of features\n",
    "#bais: \"shift\"/location of the activation function\n",
    "#activiation function is sigmoid\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e041858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate for gradient descent\n",
    "#explain why you needa hyperparameter tune this\n",
    "LR = 0.0015\n",
    "\n",
    "#number of random starting points to take\n",
    "n_iters = 100\n",
    "\n",
    "#number of steps to take in GD\n",
    "n_steps = 1000\n",
    "\n",
    "#feature inputs -> dotted weights, + bias -> y = sigmoid(x) -> find_loss(y)\n",
    "\n",
    "#we can write in terms of wegiths and biases (substitute into the find loss function)\n",
    "#feature inputs -> dotted weights, + bias -> y = sigmoid(x) -> find_loss(y) -> \n",
    "\n",
    "weights, biases = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b0963b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tanh, ReLU (less computation time)\n",
    "#Why choose sigmoid?\n",
    "\n",
    "#Activation function: \n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Computes sigmoid function to calculate probability based on single-value output of logistic regression\n",
    "    and predictions. \n",
    "    Input: Computed prediction value\n",
    "    Returns: scalar probability between (0, 1)\n",
    "    \"\"\"\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def cross_entropy(predictions, targets, epsilon = 1e-14):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between predicted probabilities and actual 0/1 classifications. \n",
    "    Input: predictions vector of predicted classes' probabilities\n",
    "           targets vector of actual 0/1 classes\n",
    "    Returns: scalar representing loss\n",
    "    \"\"\"\n",
    "    n = predictions.shape[0]\n",
    "    return -(1/n) * np.sum(targets*np.log(predictions + epsilon) + (1-targets)*np.log(1 - predictions + epsilon))\n",
    "\n",
    "#E'(weights, biases)\n",
    "#Other activation function and their derivatives given here: https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
    "def calc_dir(x, bias, predicted, actual):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions. \n",
    "    Input: weights = coefficients for features\n",
    "           bias = single-value added to prediction output     \n",
    "           predicted = predicted 0/1 classes for classification output\n",
    "           actual = actual 0/1 classes for classification output\n",
    "    Returns: tuple of 2 elements\n",
    "             gradient descent vector <dw, db> = vector of greatest descent for weights and biases, respectively\n",
    "    \"\"\"\n",
    "    N = len(weights)\n",
    "\n",
    "    dW = (1/N) * 2 * np.dot(x.T, predicted - actual)\n",
    "    dB = (1/N) * 2 * np.sum(predicted - actual)\n",
    "\n",
    "    return [dW, dB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f33caf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(weights, bias, x, y, LR, report=False):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to optimize initial starting weight and biases\n",
    "    \n",
    "    Input: x = training set containing input features\n",
    "           y = training set containing expected classification\n",
    "           weights = n-d vector/numpy_array\n",
    "           bias = scalar\n",
    "           LR = scalar, learning rate\n",
    "    Returns: tuple of 2 elements, (weights, bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        #for each row of features, we generate a corresponding number by multiplying each weight by feature value\n",
    "        predicted_vals = np.dot(x, weights.T) + bias\n",
    "        \n",
    "        #for each feature value, we predict its class probability utilizing the sigmoid function\n",
    "        predicted_probs = sigmoid(predicted_vals)\n",
    "\n",
    "        if report:\n",
    "            print(\"On step \" + str(i) + \"th step, loss equals \" + str(cross_entropy(predicted_probs, y)))\n",
    "        \n",
    "        #calculated derivatives\n",
    "        derivs = calc_dir(x, bias, predicted_probs, y)\n",
    "        dW = derivs[0]\n",
    "        dB = derivs[1]\n",
    "        \n",
    "        #\"descent\" down\n",
    "        weights -= LR * dW\n",
    "        bias -= LR * dB\n",
    "        \n",
    "    return [weights, bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "086d1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, report = False):\n",
    "    \"\"\"\n",
    "    Optimizes weights and biases given initial training set. Utilizes entire training set (must train-test-split beforehand)\n",
    "    \n",
    "    Input: x = model input of training dataset, 2darray containing m samples (entries) and n features\n",
    "           y = expected model output of training dataset, 1darray containing n classification results (0/1)\n",
    "\n",
    "    \"\"\"\n",
    "    global weights, bias\n",
    "    m, n = x.shape\n",
    "    \n",
    "    #we take n_iters random starting points\n",
    "    for _ in range(n_iters):\n",
    "        #random starting points: vector/np_array of size n\n",
    "        weights = np.random.rand(n) * 10\n",
    "        #random starting points: random bias\n",
    "        bias = np.random.rand(1)[0]\n",
    "\n",
    "        res = gradient_descent(weights, bias, x, y, LR, report)\n",
    "        weights = res[0]\n",
    "        bias = res[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5a6f2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(x):\n",
    "    \"\"\"\n",
    "    Utilizes pre-optimized weights and biases to outputs class probability given m entries of nd-vector of features\n",
    "    \n",
    "    Input: m by n matrix of feature\n",
    "    Output: m-d vector of class probabilities for each entry\n",
    "    \"\"\"\n",
    "    predicted_vals = np.dot(x, weights.T) + bias\n",
    "    predicted_probs = sigmoid(predicted_vals)\n",
    "    \n",
    "    return predicted_probs\n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    \"\"\"\n",
    "    Utilizes pre-optimized weights and biases to outputs class given m entries of nd-vector of features\n",
    "    \n",
    "    Input: m by n matrix of feature\n",
    "    Output: m-d vector of 0/1 class for each entry\n",
    "    \"\"\"\n",
    "\n",
    "    x = predict_probs(x)\n",
    "\n",
    "    x = [0 if i < 0.5 else 1 for i in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "deca0329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-113-874f6cf9979a>:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "(114,)\n",
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, plot_confusion_matrix\n",
    "\n",
    "data = load_breast_cancer()\n",
    "x, y = data.data, data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "\n",
    "train(x_train, y_train)\n",
    "\n",
    "y_pred = predict(x_test)\n",
    "print(len(y_pred))\n",
    "print(y_test.shape)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d137ddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(array, index = ['True Yes', 'True No'],\n",
    "                  columns = ['Predicted Yes', 'Predicted No'])\n",
    "\n",
    "plt.figure()\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874232ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
